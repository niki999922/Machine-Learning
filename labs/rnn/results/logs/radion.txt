2020-12-23 22:43:31.356641: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-12-23 22:43:31.356804: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-12-23 22:43:31.688057: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
Epoch 1/30
8751/8751 [==============================] - 660s 75ms/step - loss: 2.9903

Epoch 00001: loss improved from inf to 2.93927, saving model to results/radion/epoch_01__loss_2.9393.hdf5
Epoch 2/30
8751/8751 [==============================] - 777s 89ms/step - loss: 2.8325

Epoch 00002: loss improved from 2.93927 to 2.80722, saving model to results/radion/epoch_02__loss_2.8072.hdf5
Epoch 3/30
8751/8751 [==============================] - 780s 89ms/step - loss: 2.7367

Epoch 00003: loss improved from 2.80722 to 2.71725, saving model to results/radion/epoch_03__loss_2.7173.hdf5
Epoch 4/30
8751/8751 [==============================] - 793s 91ms/step - loss: 2.6419

Epoch 00004: loss improved from 2.71725 to 2.61675, saving model to results/radion/epoch_04__loss_2.6167.hdf5
Epoch 5/30
8751/8751 [==============================] - 786s 90ms/step - loss: 2.5358

Epoch 00005: loss improved from 2.61675 to 2.51463, saving model to results/radion/epoch_05__loss_2.5146.hdf5
Epoch 6/30
8751/8751 [==============================] - 779s 89ms/step - loss: 2.4385

Epoch 00006: loss improved from 2.51463 to 2.42233, saving model to results/radion/epoch_06__loss_2.4223.hdf5
Epoch 7/30
8751/8751 [==============================] - 746s 85ms/step - loss: 2.3572

Epoch 00007: loss improved from 2.42233 to 2.34317, saving model to results/radion/epoch_07__loss_2.3432.hdf5
Epoch 8/30
8751/8751 [==============================] - 728s 83ms/step - loss: 2.2880

Epoch 00008: loss improved from 2.34317 to 2.27850, saving model to results/radion/epoch_08__loss_2.2785.hdf5
Epoch 9/30
8751/8751 [==============================] - 473s 54ms/step - loss: 2.2322

Epoch 00009: loss improved from 2.27850 to 2.22297, saving model to results/radion/epoch_09__loss_2.2230.hdf5
Epoch 10/30
8751/8751 [==============================] - 451s 51ms/step - loss: 2.1789

Epoch 00010: loss improved from 2.22297 to 2.17734, saving model to results/radion/epoch_10__loss_2.1773.hdf5
Epoch 11/30
8751/8751 [==============================] - 473s 54ms/step - loss: 2.1398

Epoch 00011: loss improved from 2.17734 to 2.13823, saving model to results/radion/epoch_11__loss_2.1382.hdf5
Epoch 12/30
8751/8751 [==============================] - 366s 42ms/step - loss: 2.1068

Epoch 00012: loss improved from 2.13823 to 2.10521, saving model to results/radion/epoch_12__loss_2.1052.hdf5
Epoch 13/30
8751/8751 [==============================] - 304s 35ms/step - loss: 2.0748

Epoch 00013: loss improved from 2.10521 to 2.07537, saving model to results/radion/epoch_13__loss_2.0754.hdf5
Epoch 14/30
8751/8751 [==============================] - 304s 35ms/step - loss: 2.0496

Epoch 00014: loss improved from 2.07537 to 2.05144, saving model to results/radion/epoch_14__loss_2.0514.hdf5
Epoch 15/30
8751/8751 [==============================] - 319s 36ms/step - loss: 2.0468

Epoch 00015: loss did not improve from 2.05144
Epoch 16/30
8751/8751 [==============================] - 308s 35ms/step - loss: 2.0137

Epoch 00016: loss improved from 2.05144 to 2.01211, saving model to results/radion/epoch_16__loss_2.0121.hdf5
Epoch 17/30
8751/8751 [==============================] - 307s 35ms/step - loss: 1.9949

Epoch 00017: loss improved from 2.01211 to 1.99361, saving model to results/radion/epoch_17__loss_1.9936.hdf5
Epoch 18/30
8751/8751 [==============================] - 301s 34ms/step - loss: 1.9742

Epoch 00018: loss improved from 1.99361 to 1.97455, saving model to results/radion/epoch_18__loss_1.9746.hdf5
Epoch 19/30
8751/8751 [==============================] - 285s 33ms/step - loss: 1.9604

Epoch 00019: loss improved from 1.97455 to 1.96240, saving model to results/radion/epoch_19__loss_1.9624.hdf5
Epoch 20/30
8751/8751 [==============================] - 276s 32ms/step - loss: 1.9398

Epoch 00020: loss improved from 1.96240 to 1.94527, saving model to results/radion/epoch_20__loss_1.9453.hdf5
Epoch 21/30
8751/8751 [==============================] - 279s 32ms/step - loss: 1.9313

Epoch 00021: loss improved from 1.94527 to 1.93296, saving model to results/radion/epoch_21__loss_1.9330.hdf5
Epoch 22/30
8751/8751 [==============================] - 281s 32ms/step - loss: 1.9594

Epoch 00022: loss did not improve from 1.93296
Epoch 23/30
8751/8751 [==============================] - 276s 32ms/step - loss: 1.9107

Epoch 00023: loss improved from 1.93296 to 1.91498, saving model to results/radion/epoch_23__loss_1.9150.hdf5
Epoch 24/30
8751/8751 [==============================] - 280s 32ms/step - loss: 1.8983

Epoch 00024: loss improved from 1.91498 to 1.90573, saving model to results/radion/epoch_24__loss_1.9057.hdf5
Epoch 25/30
8751/8751 [==============================] - 281s 32ms/step - loss: 1.8847

Epoch 00025: loss improved from 1.90573 to 1.89576, saving model to results/radion/epoch_25__loss_1.8958.hdf5
Epoch 26/30
8751/8751 [==============================] - 281s 32ms/step - loss: 1.8997

Epoch 00026: loss did not improve from 1.89576
Epoch 27/30
8751/8751 [==============================] - 282s 32ms/step - loss: 1.8739

Epoch 00027: loss improved from 1.89576 to 1.88000, saving model to results/radion/epoch_27__loss_1.8800.hdf5
Epoch 28/30
8751/8751 [==============================] - 294s 34ms/step - loss: 1.8620

Epoch 00028: loss improved from 1.88000 to 1.86886, saving model to results/radion/epoch_28__loss_1.8689.hdf5
Epoch 29/30
8751/8751 [==============================] - 281s 32ms/step - loss: 1.8485

Epoch 00029: loss improved from 1.86886 to 1.85820, saving model to results/radion/epoch_29__loss_1.8582.hdf5
Epoch 30/30
8751/8751 [==============================] - 285s 33ms/step - loss: 1.8441

Epoch 00030: loss improved from 1.85820 to 1.85038, saving model to results/radion/epoch_30__loss_1.8504.hdf5
