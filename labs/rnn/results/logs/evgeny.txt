2020-12-23 22:43:59.820421: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-12-23 22:43:59.820655: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-12-23 22:44:00.171060: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
Epoch 1/30
2062/2062 [==============================] - 157s 75ms/step - loss: 3.1303

Epoch 00001: loss improved from inf to 3.09559, saving model to results/evgeny/epoch_01__loss_3.0956.hdf5
Epoch 2/30
2062/2062 [==============================] - 166s 81ms/step - loss: 3.0440

Epoch 00002: loss improved from 3.09559 to 3.03164, saving model to results/evgeny/epoch_02__loss_3.0316.hdf5
Epoch 3/30
2062/2062 [==============================] - 167s 81ms/step - loss: 2.9758

Epoch 00003: loss improved from 3.03164 to 2.96715, saving model to results/evgeny/epoch_03__loss_2.9671.hdf5
Epoch 4/30
2062/2062 [==============================] - 182s 88ms/step - loss: 2.9343

Epoch 00004: loss improved from 2.96715 to 2.92034, saving model to results/evgeny/epoch_04__loss_2.9203.hdf5
Epoch 5/30
2062/2062 [==============================] - 191s 92ms/step - loss: 2.8865

Epoch 00005: loss improved from 2.92034 to 2.87957, saving model to results/evgeny/epoch_05__loss_2.8796.hdf5
Epoch 6/30
2062/2062 [==============================] - 192s 93ms/step - loss: 2.8611

Epoch 00006: loss improved from 2.87957 to 2.85735, saving model to results/evgeny/epoch_06__loss_2.8574.hdf5
Epoch 7/30
2062/2062 [==============================] - 195s 95ms/step - loss: 2.8402

Epoch 00007: loss improved from 2.85735 to 2.84013, saving model to results/evgeny/epoch_07__loss_2.8401.hdf5
Epoch 8/30
2062/2062 [==============================] - 200s 97ms/step - loss: 2.8199

Epoch 00008: loss improved from 2.84013 to 2.82254, saving model to results/evgeny/epoch_08__loss_2.8225.hdf5
Epoch 9/30
2062/2062 [==============================] - 205s 99ms/step - loss: 2.8104

Epoch 00009: loss improved from 2.82254 to 2.80759, saving model to results/evgeny/epoch_09__loss_2.8076.hdf5
Epoch 10/30
2062/2062 [==============================] - 205s 99ms/step - loss: 2.8007

Epoch 00010: loss improved from 2.80759 to 2.79373, saving model to results/evgeny/epoch_10__loss_2.7937.hdf5
Epoch 11/30
2062/2062 [==============================] - 202s 98ms/step - loss: 2.7797

Epoch 00011: loss improved from 2.79373 to 2.77714, saving model to results/evgeny/epoch_11__loss_2.7771.hdf5
Epoch 12/30
2062/2062 [==============================] - 206s 100ms/step - loss: 2.7630

Epoch 00012: loss improved from 2.77714 to 2.75948, saving model to results/evgeny/epoch_12__loss_2.7595.hdf5
Epoch 13/30
2062/2062 [==============================] - 216s 105ms/step - loss: 2.7491

Epoch 00013: loss improved from 2.75948 to 2.74361, saving model to results/evgeny/epoch_13__loss_2.7436.hdf5
Epoch 14/30
2062/2062 [==============================] - 213s 103ms/step - loss: 2.7317

Epoch 00014: loss improved from 2.74361 to 2.72915, saving model to results/evgeny/epoch_14__loss_2.7291.hdf5
Epoch 15/30
2062/2062 [==============================] - 208s 101ms/step - loss: 2.7130

Epoch 00015: loss did not improve from 2.72915
Epoch 16/30
2062/2062 [==============================] - 212s 103ms/step - loss: 2.6999

Epoch 00016: loss improved from 2.72915 to 2.69842, saving model to results/evgeny/epoch_16__loss_2.6984.hdf5
Epoch 17/30
2062/2062 [==============================] - 218s 106ms/step - loss: 2.6788

Epoch 00017: loss improved from 2.69842 to 2.68077, saving model to results/evgeny/epoch_17__loss_2.6808.hdf5
Epoch 18/30
2062/2062 [==============================] - 220s 107ms/step - loss: 2.6584

Epoch 00018: loss improved from 2.68077 to 2.66518, saving model to results/evgeny/epoch_18__loss_2.6652.hdf5
Epoch 19/30
2062/2062 [==============================] - 217s 105ms/step - loss: 2.6503

Epoch 00019: loss improved from 2.66518 to 2.64851, saving model to results/evgeny/epoch_19__loss_2.6485.hdf5
Epoch 20/30
2062/2062 [==============================] - 210s 102ms/step - loss: 2.6313

Epoch 00020: loss improved from 2.64851 to 2.63015, saving model to results/evgeny/epoch_20__loss_2.6301.hdf5
Epoch 21/30
2062/2062 [==============================] - 210s 102ms/step - loss: 2.6091

Epoch 00021: loss improved from 2.63015 to 2.61271, saving model to results/evgeny/epoch_21__loss_2.6127.hdf5
Epoch 22/30
2062/2062 [==============================] - 215s 104ms/step - loss: 2.5924

Epoch 00022: loss improved from 2.61271 to 2.59419, saving model to results/evgeny/epoch_22__loss_2.5942.hdf5
Epoch 23/30
2062/2062 [==============================] - 220s 107ms/step - loss: 2.5751

Epoch 00023: loss improved from 2.59419 to 2.57754, saving model to results/evgeny/epoch_23__loss_2.5775.hdf5
Epoch 24/30
2062/2062 [==============================] - 219s 106ms/step - loss: 2.5553

Epoch 00024: loss improved from 2.57754 to 2.55681, saving model to results/evgeny/epoch_24__loss_2.5568.hdf5
Epoch 25/30
2062/2062 [==============================] - 216s 105ms/step - loss: 2.5414

Epoch 00025: loss improved from 2.55681 to 2.54310, saving model to results/evgeny/epoch_25__loss_2.5431.hdf5
Epoch 26/30
2062/2062 [==============================] - 214s 104ms/step - loss: 2.5222

Epoch 00026: loss improved from 2.54310 to 2.52018, saving model to results/evgeny/epoch_26__loss_2.5202.hdf5
Epoch 27/30
2062/2062 [==============================] - 226s 110ms/step - loss: 2.5070

Epoch 00027: loss improved from 2.52018 to 2.50378, saving model to results/evgeny/epoch_27__loss_2.5038.hdf5
Epoch 28/30
2062/2062 [==============================] - 219s 106ms/step - loss: 2.4751

Epoch 00028: loss improved from 2.50378 to 2.48280, saving model to results/evgeny/epoch_28__loss_2.4828.hdf5
Epoch 29/30
2062/2062 [==============================] - 194s 94ms/step - loss: 2.4549

Epoch 00029: loss improved from 2.48280 to 2.46191, saving model to results/evgeny/epoch_29__loss_2.4619.hdf5
Epoch 30/30
2062/2062 [==============================] - 191s 93ms/step - loss: 2.4335

Epoch 00030: loss improved from 2.46191 to 2.44386, saving model to results/evgeny/epoch_30__loss_2.4439.hdf5